# ğŸš€ Optimizaciones de Rendimiento - Sistema Taller Diego

## Objetivo: Respuesta < 1 segundo en todas las operaciones

### âœ… Optimizaciones Implementadas

#### 1. **Base de Datos**

**Ãndices Creados:**
```sql
-- Ãndices en tabla auditoria (ya implementados)
CREATE INDEX idx_auditoria_modulo_fecha ON auditoria(modulo, fecha DESC);
CREATE INDEX idx_auditoria_tabla_registro ON auditoria(tabla, registro_id);
CREATE INDEX idx_auditoria_usuario ON auditoria(usuario);
CREATE INDEX idx_auditoria_accion ON auditoria(accion);
CREATE INDEX idx_auditoria_fecha ON auditoria(fecha DESC);

-- Ãndices adicionales recomendados para productos
CREATE INDEX IF NOT EXISTS idx_productos_nombre ON productos(nombre);
CREATE INDEX IF NOT EXISTS idx_productos_categoria ON productos(categoria);
CREATE INDEX IF NOT EXISTS idx_productos_codbarras ON productos("codBarras");
```

**Connection Pooling:**
```python
# En db/base.py (ya implementado)
engine = create_engine(
    settings.DATABASE_URL,
    pool_size=10,          # Conexiones permanentes
    max_overflow=20,       # Conexiones adicionales bajo carga
    pool_pre_ping=True     # Verificar conexiÃ³n antes de usar
)
```

#### 2. **CachÃ© en Memoria**

**Sistema de cachÃ© implementado:**
- TTL configurable (default: 120 segundos para listas)
- InvalidaciÃ³n por patrones
- EstadÃ­sticas de hit rate
- GeneraciÃ³n automÃ¡tica de claves

**Uso:**
```python
# Lista de productos cacheada por 2 minutos
cached = cache.get('productos_list_all')
if cached:
    return cached

productos = repo.get_all()
cache.set('productos_list_all', productos, ttl_seconds=120)
```

#### 3. **CompresiÃ³n de Respuestas**

**GZip Middleware (ya implementado en main.py):**
```python
app.add_middleware(GZipMiddleware, minimum_size=1000)
```
- Reduce tamaÃ±o de respuestas JSON en ~70%
- Solo para respuestas > 1KB
- Ahorro de ancho de banda

#### 4. **OptimizaciÃ³n de Queries**

**LÃ­mites por defecto:**
```python
# Evitar consultas sin lÃ­mite
def get_all(self):
    return self.db.query(Producto).order_by(Producto.id.desc()).limit(1000).all()

# AuditorÃ­a con lÃ­mite razonable
def get_by_registro(db, tabla, registro_id, limit=100):
    return query.limit(limit).all()
```

**PaginaciÃ³n:**
```python
# En endpoints de auditorÃ­a
limit: int = Query(100, ge=1, le=1000)
skip: int = Query(0, ge=0)
```

#### 5. **Headers de CachÃ© HTTP**

**Cache-Control headers (ya implementado):**
```python
# En main.py middleware
if request.url.path.startswith("/api/v1/"):
    response.headers["Cache-Control"] = "public, max-age=300"  # 5 minutos
```

### ğŸ“Š MÃ©tricas de Rendimiento

#### Tiempos Esperados (< 1 segundo):

| OperaciÃ³n | Sin CachÃ© | Con CachÃ© | Target |
|-----------|-----------|-----------|--------|
| GET /productos/ (lista completa) | ~400ms | ~50ms | < 1s âœ… |
| GET /productos/{id} | ~100ms | ~20ms | < 1s âœ… |
| POST /productos/ | ~200ms | N/A | < 1s âœ… |
| PUT /productos/{id} | ~250ms | N/A | < 1s âœ… |
| GET /auditoria/ (100 registros) | ~300ms | ~80ms | < 1s âœ… |
| GET /productos/{id}/historial | ~150ms | ~40ms | < 1s âœ… |

#### Factores que Afectan el Rendimiento:

**âœ… Optimizado:**
- Ãndices en columnas frecuentemente consultadas
- Connection pooling (10-30 conexiones)
- CachÃ© en memoria para lecturas
- CompresiÃ³n GZip
- LÃ­mites en queries
- Eager loading donde es necesario

**âš ï¸ Posibles Cuellos de Botella:**
- Latencia de red a Supabase (depende de ubicaciÃ³n)
- Queries sin Ã­ndices en tablas grandes
- Respuestas muy grandes sin paginaciÃ³n
- AuditorÃ­a sin lÃ­mite en historiales largos

### ğŸ§ª Pruebas de Rendimiento

#### 1. Prueba de Latencia Simple

```bash
# Medir tiempo de respuesta
time curl -s http://localhost:8000/api/v1/productos/ > /dev/null

# Con output
curl -w "\nTiempo total: %{time_total}s\n" -s http://localhost:8000/api/v1/productos/ -o /dev/null
```

#### 2. Prueba de Carga con Apache Bench

```bash
# Instalar ab
sudo apt-get install apache2-utils  # Ubuntu/Debian
brew install apache2                  # macOS

# 100 requests, 10 concurrentes
ab -n 100 -c 10 http://localhost:8000/api/v1/productos/

# Con headers personalizados
ab -n 100 -c 10 -H "X-Usuario: Test" http://localhost:8000/api/v1/productos/
```

#### 3. Prueba con Python (Script Incluido)

```bash
cd backend
python test_performance.py
```

#### 4. Verificar EstadÃ­sticas de CachÃ©

```python
# Endpoint para ver estadÃ­sticas
GET /api/v1/cache/stats

# Respuesta esperada:
{
    "size": 5,
    "hits": 847,
    "misses": 123,
    "hit_rate": "87.32%"
}
```

### ğŸ“ˆ Recomendaciones Adicionales

#### Para ProducciÃ³n:

1. **Redis en lugar de cachÃ© en memoria:**
```bash
pip install redis
```
```python
import redis
cache_client = redis.Redis(host='localhost', port=6379, db=0)
```

2. **CDN para archivos estÃ¡ticos:**
- Servir CSS, JS, imÃ¡genes desde CDN
- Reducir carga en servidor backend

3. **Load Balancer:**
- MÃºltiples instancias del backend
- NGINX como reverse proxy

4. **Monitoring:**
```bash
pip install prometheus-fastapi-instrumentator
```

5. **Database Read Replicas:**
- Lecturas en replicas
- Escrituras en master

#### Optimizaciones Frontend:

1. **Lazy Loading de imÃ¡genes**
2. **Debounce en bÃºsquedas** (ya implementado)
3. **Virtual scrolling para listas grandes**
4. **Service Worker para cachÃ© offline** (ya implementado)
5. **Compression en nginx:**
```nginx
gzip on;
gzip_types text/plain application/json;
gzip_min_length 1000;
```

### ğŸ” Monitoreo Continuo

#### Logs de Performance

```python
import time

@app.middleware("http")
async def log_performance(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    # Alertar si > 1 segundo
    if process_time > 1.0:
        logger.warning(f"SLOW REQUEST: {request.url.path} took {process_time:.2f}s")
    
    response.headers["X-Process-Time"] = str(process_time)
    return response
```

#### Query Profiling

```python
# En PostgreSQL
EXPLAIN ANALYZE SELECT * FROM productos WHERE categoria = 'Filtros';

# Ver queries lentas
SELECT query, mean_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

### âœ… Checklist de OptimizaciÃ³n

- [x] Ãndices en tabla auditoria
- [x] Connection pooling configurado
- [x] CachÃ© en memoria implementado
- [x] GZip compression habilitado
- [x] LÃ­mites en queries
- [x] PaginaciÃ³n en endpoints
- [x] Headers de cachÃ© HTTP
- [x] Middleware de performance tracking
- [ ] Ãndices adicionales en productos/servicios
- [ ] Tests de carga automatizados
- [ ] Monitoring con Prometheus
- [ ] CDN para estÃ¡ticos
- [ ] Redis para producciÃ³n

### ğŸ“ Notas

- El cachÃ© actual es **en memoria**: Se pierde al reiniciar el servidor
- Para **alta disponibilidad**: Migrar a Redis
- **Supabase**: Ya tiene optimizaciones de PostgreSQL
- **Network latency**: Principal factor fuera de nuestro control
- **Ãndices**: Revisar periÃ³dicamente con tablas grandes (>10k registros)

### ğŸ¯ Casos de Prueba EspecÃ­ficos

#### Test 1: Lista de productos completa
```bash
# Debe responder en < 500ms (primera vez) y < 100ms (con cachÃ©)
time curl http://localhost:8000/api/v1/productos/
```

#### Test 2: BÃºsqueda por cÃ³digo de barras
```bash
# Debe responder en < 200ms (hay Ã­ndice)
time curl http://localhost:8000/api/v1/productos/barcode/AUDIT999
```

#### Test 3: Historial de auditorÃ­a
```bash
# Debe responder en < 300ms (Ã­ndice compuesto)
time curl http://localhost:8000/api/v1/productos/5/historial
```

#### Test 4: Consulta de auditorÃ­a con filtros
```bash
# Debe responder en < 400ms (mÃºltiples Ã­ndices)
time curl "http://localhost:8000/api/v1/auditoria/?modulo=inventario&limit=100"
```

---

**Resultado Final Esperado:** âœ… Todas las operaciones < 1 segundo
